{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d94e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T08:43:36.251115Z",
     "start_time": "2021-05-13T08:43:36.248113Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64820748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T08:43:39.219660Z",
     "start_time": "2021-05-13T08:43:36.396363Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as tF\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from loss import MaximalCodingRateReduction, label_to_membership\n",
    "import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1fb1af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T08:43:39.228521Z",
     "start_time": "2021-05-13T08:43:39.221237Z"
    }
   },
   "outputs": [],
   "source": [
    "class MCR2(nn.Module):\n",
    "    def __init__(self, eps=0.1):\n",
    "        super(MCR2, self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def compute_discrimn_loss(self, Z):\n",
    "        \"\"\"Theoretical Discriminative Loss.\"\"\"\n",
    "        d, n = Z.shape\n",
    "        I = torch.eye(d).to(Z.device)\n",
    "        scalar = d / (n * self.eps)\n",
    "        logdet = torch.logdet(I + scalar * Z @ Z.T)\n",
    "        return logdet / 2.\n",
    "\n",
    "    def compute_compress_loss(self, Z, Pi):\n",
    "        \"\"\"Theoretical Compressive Loss.\"\"\"\n",
    "        d, n = Z.shape\n",
    "        I = torch.eye(d).to(Z.device)\n",
    "        compress_loss = 0.\n",
    "        for j in range(Pi.shape[1]):\n",
    "            trPi = Pi[:, j].sum()\n",
    "            scalar = d / (trPi * self.eps)\n",
    "            log_det = torch.logdet(I + scalar * Z @ Pi[:, j].diag() @ Z.T)\n",
    "            compress_loss += trPi / (2 * n) * log_det\n",
    "        return compress_loss\n",
    "\n",
    "    def forward(self, Z, Pi):\n",
    "        discrimn_loss = self.compute_discrimn_loss(Z.T)\n",
    "        compress_loss = self.compute_compress_loss(Z.T, Pi)\n",
    "        total_loss = discrimn_loss - compress_loss\n",
    "        return -total_loss, discrimn_loss.item(), compress_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f9f78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T08:43:39.240198Z",
     "start_time": "2021-05-13T08:43:39.230773Z"
    }
   },
   "outputs": [],
   "source": [
    "class MCR2Variational(nn.Module):\n",
    "    \"\"\"Equation 9 in writeup. \"\"\"\n",
    "    def __init__(self, eps, mu):\n",
    "        super(MCR2Variational, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.mu = mu\n",
    "        \n",
    "    def loss_discrimn(self, Z):\n",
    "        d, n = Z.shape\n",
    "        I = torch.eye(d).to(Z.device)\n",
    "        return 0.5 * torch.logdet(I + d / (n * self.eps) * Z @ Z.T)\n",
    "\n",
    "    def loss_compress(self, Z, Pi, Us):\n",
    "        d, n = Z.shape\n",
    "        I = torch.eye(d).to(Z.device)\n",
    "        compress_loss = 0.\n",
    "        for j in range(Pi.shape[1]):\n",
    "            trPi_j = Pi[:, j].sum()\n",
    "            scalar_j = trPi_j / (2 * n)\n",
    "            norms = torch.linalg.norm(Us[j], axis=0, keepdims=True, ord=2) ** 2\n",
    "            compress_loss += scalar_j * torch.log(1 + d / (trPi_j * self.eps) * norms).sum()\n",
    "        return compress_loss\n",
    "\n",
    "    def reg_U(self, Z, Pi, Us):\n",
    "        loss_reg = 0.\n",
    "        for j in range(Pi.shape[1]):\n",
    "            loss_reg += torch.linalg.norm((Z @ Pi[:, j].diag() @ Z.T) - (Us[j] @ Us[j].T), ord='fro') ** 2\n",
    "        return 0.5 * loss_reg\n",
    "    \n",
    "    def forward(self, Z, Pi, Us):\n",
    "        loss_R = self.loss_discrimn(Z.T)\n",
    "        loss_Rc = self.loss_compress(Z.T, Pi, Us)\n",
    "        loss_reg_U = self.mu * self.reg_U(Z.T, Pi, Us)\n",
    "        loss_obj = loss_R - loss_Rc - loss_reg_U\n",
    "        return -loss_obj, loss_R.item(), loss_Rc.item(), loss_reg_U.item()\n",
    "    \n",
    "class Simple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple, self).__init__()\n",
    "        self.linear1 = nn.Linear(3, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(3, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return F.normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da286c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T09:47:53.637967Z",
     "start_time": "2021-05-13T09:47:53.633032Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(a, b, c):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(np.arange(len(a)), a, label=r'$\\Delta R$')\n",
    "    ax.plot(np.arange(len(b)), b, label=r'$R$')\n",
    "    ax.plot(np.arange(len(c)), c, label=r'$R_c$')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_params(params):\n",
    "    fig, ax = plt.subplots(ncols=params.shape[0])\n",
    "    for j in range(params.shape[0]):\n",
    "        im = ax[j].imshow(params[j])\n",
    "        ax[j].set_title(f'U{j}')\n",
    "    fig.colorbar(im, pad=0.02, drawedges=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4dce86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T09:47:53.816761Z",
     "start_time": "2021-05-13T09:47:53.810440Z"
    }
   },
   "outputs": [],
   "source": [
    "# data\n",
    "n = 100\n",
    "X1 = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([1., 0., 0.]), 0.01*torch.eye(3)).sample([n])\n",
    "X2 = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([0., 1., 0.]), 0.01*torch.eye(3)).sample([n])\n",
    "X = torch.cat([X1, X2])\n",
    "y = torch.cat([torch.tensor(0).repeat(n), torch.tensor(1).repeat(n)])\n",
    "Pi = label_to_membership(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd03bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:43:25.985833Z",
     "start_time": "2021-05-12T00:43:25.984025Z"
    }
   },
   "source": [
    "## Original MCR2 objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e3794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T09:48:01.752957Z",
     "start_time": "2021-05-13T09:47:54.682986Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = Simple()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = MCR2(eps=0.1)\n",
    "\n",
    "\n",
    "all_loss_true, all_loss_discrimn, all_loss_compress = [], [], []\n",
    "for epoch in range(5000):\n",
    "    optimizer.zero_grad()\n",
    "    Z = net(X)\n",
    "    loss_true, loss_discrimn, loss_compress = criterion(Z, Pi)\n",
    "    all_loss_true.append(-loss_true.item())\n",
    "    all_loss_discrimn.append(loss_discrimn)\n",
    "    all_loss_compress.append(loss_compress)\n",
    "    print('{} | {:.5f} {:.5f} {:.5f}'.format(epoch, -loss_true.item(), loss_discrimn, loss_compress))\n",
    "    loss_true.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "Z = Z.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86567ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T09:49:15.225214Z",
     "start_time": "2021-05-13T09:49:15.102663Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(Z @ Z.T, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88515cae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T09:49:16.887006Z",
     "start_time": "2021-05-13T09:49:16.695863Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_loss(all_loss_true, all_loss_discrimn, all_loss_compress)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39edc0df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T01:28:01.466632Z",
     "start_time": "2021-05-12T01:28:01.464569Z"
    }
   },
   "source": [
    "## Variational Form - Equation 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c5e21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T09:28:44.479890Z",
     "start_time": "2021-05-13T09:28:44.473000Z"
    }
   },
   "outputs": [],
   "source": [
    "mu = 5.\n",
    "net_lr = 0.001\n",
    "param_lr = 0.001\n",
    "net = Simple()\n",
    "\n",
    "init_Us = []\n",
    "with torch.no_grad():\n",
    "    Z = net(X)\n",
    "    for j in range(2):\n",
    "        U, S, _ = torch.linalg.svd(Z.T @ Pi[:, j].diag() @ Z)\n",
    "        init_Us.append(U @ (S**0.5).diag())\n",
    "#         init_Us.append(U)\n",
    "init_Us = torch.stack(init_Us)\n",
    "Us = nn.Parameter(\n",
    "    init_Us, \n",
    "    requires_grad=True\n",
    "    )\n",
    "\n",
    "criterion_mcr2var = MCR2Variational(0.1, mu)\n",
    "optimizer_net = optim.SGD(net.parameters(), lr=net_lr)\n",
    "optimizer_Us = optim.SGD([Us], lr=param_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5cc6ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T09:29:40.184587Z",
     "start_time": "2021-05-13T09:28:44.779293Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_loss_true, all_loss_discrimn, all_loss_compress, all_loss_reg = [], [], [], []\n",
    "for epoch in range(20000):\n",
    "    optimizer_net.zero_grad()\n",
    "    optimizer_Us.zero_grad()\n",
    "    Z = net(X)\n",
    "    loss_true, loss_discrimn, loss_compress, loss_reg = criterion_mcr2var(Z, Pi, Us)\n",
    "    all_loss_true.append(loss_discrimn - loss_compress)\n",
    "    all_loss_discrimn.append(loss_discrimn)\n",
    "    all_loss_compress.append(loss_compress)\n",
    "    all_loss_reg.append(loss_reg)\n",
    "#     print('{} | {:.8f} {:.8f} {:.8f} {:.8f}'.format(epoch, -loss_true.item(), loss_discrimn, loss_compress, loss_reg))\n",
    "    loss_true.backward()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        optimizer_net.step()\n",
    "    if epoch % 1 == 0:\n",
    "        optimizer_Us.step()\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        plt.imshow(Z.detach() @ Z.detach().T, cmap='Blues')\n",
    "        plt.title(f'step{epoch}')\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    \n",
    "Z = Z.detach()\n",
    "Us = Us.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15378d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T09:29:40.815952Z",
     "start_time": "2021-05-13T09:29:40.187130Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_loss(all_loss_true, all_loss_discrimn, all_loss_compress)\n",
    "plot_params(Us)\n",
    "plt.imshow(Z @ Z.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
